---
title: Chapter 5 Problems and Notes
output: html_document
---

```{r setup}
library(tidyverse)
library(rethinking)

# Load sample datsets
data(WaffleDivorce)
wd <- WaffleDivorce
data(milk)
md <- milk
```

# Notes

* p. 130 - Confirm that all the variables in `WaffleDivorce` are correlated.
```{r}
cor(wd[, c("Divorce", "MedianAgeMarriage", "Marriage")])
```

* p. 149 - Create plot in upper right corner of Figure 5.9
```{r}
# Standardize variables of interest and remove NAs
md_complete <- md |>
  mutate(mass_log = log(mass),
         across(c("kcal.per.g", "neocortex.perc", "mass_log"),
                standardize,
                .names = "{str_extract(.col, '.')}")) |>
  drop_na(k, n, m) 

# Replicate model 5.6 (p. 148)
m5_6 <- quap(
    alist(
        k ~ dnorm(mu, sigma),
        mu <- a + bm * m,
        a ~ dnorm(0, 0.2),
        bm ~ dnorm(0, 0.5),
        sigma ~ dexp(1)
    ),
    data = md_complete
)

xseq <- seq(from = min(md_complete$m) - 0.15, to = max(md_complete$m) + 0.15,
            length.out = 30)
mu <- link(m5_6, data = list(m = xseq))
mu_mean <- apply(mu, 2, mean)
mu_pi <- apply(mu, 2, PI)

post_data <- tibble(
    x = xseq,
    mu = mu_mean
  ) |>
  bind_cols(as_tibble(t(mu_pi)))

ggplot(data = post_data) +
  geom_line(aes(x = x, y = mu)) +
  geom_ribbon(aes(x = x, ymin = `5%`, ymax = `94%`),
              color = "gray", alpha = 0.3) +
  geom_point(data = md_complete, aes(x = m, y = k), color = rangi2,
             shape = "o", size = 5) +
  labs(x = "log body mass (std)", y = "kilocal per g (std)") +
  theme_minimal()
```

* p. 152 reproduce the plot in the lower right hand corner of Figure 5.9
```{r}
# Define model m5.7
m5_7 <- quap(
    alist(
        k ~ dnorm(mu, sigma),
        mu <- a + bm * m + bn * n,
        a ~ dnorm(0, 0.2),
        bm ~ dnorm(0, 0.5),
        bn ~ dnorm(0, 0.5),
        sigma ~ dexp(1)
    ),
    data = md_complete
)

# Run counterfactual holding n constant at 0
mu <- link(m5_7, data = data.frame(m = xseq, n = 0))
mu_mean <- apply(mu, 2, mean)
mu_pi <- apply(mu, 2, PI)

plot_data <- tibble(
    x = xseq,
    mu = mu_mean
) |>
bind_cols(as_tibble(t(mu_pi)))

plot_data |>
  ggplot(aes(x = x)) +
  geom_line(aes(y = mu)) +
  geom_ribbon(aes(ymin = `5%`, ymax = `94%`), color = "gray", alpha = 0.3) +
  labs(title = "Counterfactual holding N = 0", x = "log body mass (std)",
       y = "kilocal per g (std)") +
  theme_minimal()
```

# Practice

**5E1.**

The linear models (2) and (4) are multiple linear regressions, because they have more than one predictor and specific coefficients for each. Note the presence or absence of an intercept (the only difference between (2) and (4)) does not determine whether a linear model is a multiple linear regression.

The model (1) is not a multiple linear regression because it only has one predictor, namely $x_i$. Model (2) is not a multiple linear regression because, despite the presence of both $x_i$ and $z_i$, there is only one coefficient. This model is equivalent to a simple linear regression with the single predictor $y_i :=x_i - z_i$.

**5E2.**

Assuming a Gaussian model and appropriate priors on the parameters, the model for the mean in this case could be:

$$\begin{align}
A_i &\sim \text{Normal }(\mu_i, \sigma)\\
\mu_i &= \alpha + \beta_L L_i + \beta_P P_i
\end{align}$$

where $A_i$, $L_i$, and $P_i$ are the animal diversity, latitude, and plant diversity for location $i$, respectively.

**5E3.**

Assuming a Gaussian model and appropriate priors on the parameters, the model for the mean in this case could be:

$$\begin{align}
T_i &\sim \text{Normal }(\mu_i, \sigma)\\
\mu_i &= \alpha + \beta_L L_i + \beta_F F_i
\end{align}$$

where $T_i$, $L_i$, and $F_i$ are the time to PhD, size of laboratory, and amount of funding for student $i$, respectively. One should expect that both $\beta_F$ and $\beta_L$ are positive.

**5E4.**

All models except (2) are inferentially equivalent. They all essentially encode individual means for each category. Model (2) would not even work, I believe, as $\alpha$ could not be estimated: it only is effective when $A_i=B_i=C_i=D_i=0$, which is impossible as I understand the problem.

**5M1.**

Suppose we had data on weekly church attendance rates for a survey of families. In the survey are the rate of weekly church attendance (over a certain period of time) and the number of seats in the family's largest vehicle. I would guess with such data that the larger the number of seats in the vehicle would be positively correlated with weekly church attendance. However, if we also had in the survey data the number of children in the family, then the correlation between number of seats and church attendance would disappear in a model including all three variables.

**5M2.**

Suppose our outcome is the winning percentages of soccer clubs. The two predictors are the size of the club's wage budget and the average goals allowed per game. I would expect that the club's budget is positively correlated with winning percentage (they can afford more world class players) while average goals allowed would be negatively correlated (the more goals allowed per game, the less likely you are to win). The size of the budget and the goals allowed are correlated because a larger budget may indicate the presence of stronger goalkeepers or defenders on the roster that would lower the average goals allowed.

**5M3.**

A high divorce rate could cause a high marriage rate if the divorcees end up remarrying previously unmarried people in the same population. And this is more likely to happen if the age of marriage is relatively young because there is more time (a possibly desire) to remarry.

If we had the rate of remarrige in the data that would help us test this directly. If we only have the data from the book, then we could reverse the use of $M$ and $D$ from the analysis in section 5.1 to study the potential causal relationship of divorce on marriage.

**5M4.**

Our first step is to find the percentage of Mormon residents per state, collect that data, and add it to the original marriage data (`wd`).
```{r}
# Load rvest package to scrape table of LDS population by state from the web
library(rvest)

# The interwebs led me to this site, which contains a table of population of
# Mormons by state
lds_pop_url <- "https://www.worldatlas.com/articles/mormon-population-by-state.html"
lds_pop <- read_html(lds_pop_url) |>
  html_element("table") |>
  html_table()

# We're interested in the state (to match to the Waffle House data) and the
# percent population. We need to convert the percentage to a number to use it.
lds_pop1 <- lds_pop |>
  janitor::clean_names() |>
  select(state, percentage_of_mormon_residents) |>
  mutate(lds_perc = as.numeric(sub("%", "", percentage_of_mormon_residents)))

# Now add it to the original marriage data
wd_lds <- left_join(wd, lds_pop1, by = c("Location" = "state"))
# Confirm that it worked
summary(wd_lds$lds_perc)
```

Now, we estimate the model after standardizing all the variables. We will use the same priors as the book.
```{r}
wd_lds <- wd_lds |>
  mutate(age = standardize(MedianAgeMarriage),
         mar = standardize(Marriage),
         div = standardize(Divorce),
         lds = standardize(lds_perc))

# Define and fit the model
lds_mdl <- quap(
  alist(
    div ~ dnorm(mu, sigma),
    mu <- a + bm * mar + ba * age + bl * lds,
    a ~ dnorm(0, 0.2),
    bm ~ dnorm(0, 0.5),
    ba ~ dnorm(0, 0.5),
    bl ~ dnorm(0, 0.5),
    sigma ~ dexp(1)
  ),
  data = wd_lds
)

# Summarize posterior
precis(lds_mdl)

# Visualize the posterior
plot(coeftab(lds_mdl))
```

Let's look at the model's posterior predictive plots to see if improves on m5.3 from the book (cf. pg. 138).

```{r}
mu <- link(lds_mdl)

mu_mean <- apply(mu, 2, mean)
mu_pi <- apply(mu, 2, PI)

div_sim <- sim(lds_mdl, n = 1e4)
div_pi <- apply(div_sim, 2, PI)

post_pred_plot_data <- tibble(
  div = wd_lds$div,
  mu = mu_mean,
  loc = levels(wd_lds$Loc)
) |>
bind_cols(t(mu_pi)) |>
mutate(pred_diff = mu - div,
       rank = row_number(pred_diff),
       poorly_pred = if_else(rank <= 3 | rank >= 48, loc, ""))

post_pred_plot_data |>
  ggplot() +
  geom_point(aes(x = div, y = mu), shape = "o", size = 5, color = rangi2) +
  geom_segment(aes(x = div, xend = div, y = `5%`, yend = `94%`),
               color = rangi2) +
  geom_abline(slope = 1, intercept = 0, linetype = 2) +
  geom_text(aes(x = div, y = mu, label = poorly_pred), nudge_x = 0.1) +
  labs(x = "Observed divorce", y = "Predicted divorce")
```

I've labeled the states whose predictions have the largest positive and largest negative distances from the observed values. ID and UT no longer appear above the dashed line, likely because of controlling for the presence of Mormons.

**5M5.**

Let $G$ be the price of gasoline, $O$ the obesity rate, $E$ be a measure of exercise, and $R$ be a measure of eating out at restaurants. The mechanisms we are interested in can be shown in this DAG:

```{r}
library(dagitty)

g <- dagitty("dag{
  G -> E 
  G -> R
  E -> O
  R -> O 
  }")
coordinates(g) <- list(x = c(G = 0, E = -1, R = 1, O = 0),
                       y = c(G = 1, E = 2, R = 2, O = 3))
drawdag(g)
```

It's possible that there's an association between $E$ and $R$ (say, the more you exercise, the more you care about health, the less likely you are to eat out), but we are definitely interested in whether, conditional on $E$ and $R$, $G$ and $O$ are still related. A model that uses $G$, $R$, and $E$ to predict $O$ compared to a model with just $G$ predicting $O$ would allow us to understand this.

**5H1.**

Let's create the DAG with `dagitty` to check the implied conditional independencies.

```{r}
dag_5h1 <- dagitty("dag{M -> A -> D}")
impliedConditionalIndependencies(dag_5h1)
```

So, the only one implied by the DAG is that once we know $A$, $D$ and $M$ are independent. This is consistent with the data, as discussed in the chapter.

**5H2.**

Let's fit a model for the DAG $M\rightarrow A\rightarrow D$. We only need the models $M\rightarrow A$ and $A\rightarrow M$.

```{r}
# Create dataset for this model
d_5h2 <- wd |>
  select(Divorce, Marriage, MedianAgeMarriage) |>
  mutate(div = standardize(Divorce),
         mar = standardize(Marriage),
         age = standardize(MedianAgeMarriage))
m_5h2 <- quap(
  alist(
    # M -> A
    age ~ dnorm(mu_age, sigma_age),
    mu_age <- a_age + b_m * mar,
    a_age ~ dnorm(0, 0.2),
    b_m ~ dnorm(0, 0.5),
    sigma_age ~ dexp(1),
    # A -> D
    div ~ dnorm(mu, sigma),
    mu <- a + b * age,
    a ~ dnorm(0, 0.2),
    b ~ dnorm(0, 0.5),
    sigma ~ dexp(1)
  ),
  data = d_5h2
)
```

Now, let's look at the effect of halving the marriage rate.

```{r}
sim_d <- data.frame(mar = (d_5h2$Marriage / 2 - mean(d_5h2$Marriage)) /
                            sd(d_5h2$Marriage))
s <- sim(m_5h2,
         data = sim_d,
         vars = c("age", "div"))

plot_data_5h2 <- tibble(
  mar = sim_d$mar,
  mu_age = colMeans(s$age),
  mu_div = colMeans(s$div)
)

age_pi <- apply(s$age, 2, PI) |>
  t() |>
  as_tibble() |>
  `colnames<-`(c("age_lower", "age_upper"))

div_pi <- apply(s$div, 2, PI) |>
  t() |>
  as_tibble() |>
  `colnames<-`(c("div_lower", "div_upper"))

plot_data_5h2 <- bind_cols(plot_data_5h2, age_pi, div_pi)

# Plot counterfactual effects
p1 <- plot_data_5h2 |>
  ggplot(aes(x = mar)) +
  geom_line(aes(y = mu_age)) +
  geom_ribbon(aes(ymin = age_lower, ymax = age_upper), color = "gray",
                  alpha = 0.3) +
  labs(x = "Manipulated Marriage Rate",
       y = "Counterfactual Median Age at Marriage",
       title = "Counterfactual effect of halving M on A") +
  theme_minimal()

p2 <- plot_data_5h2 |>
  ggplot(aes(x = mar)) +
  geom_line(aes(y = mu_div)) +
  geom_ribbon(aes(ymin = div_lower, ymax = div_upper), color = "gray",
                  alpha = 0.3) +
  labs(x = "Manipulated Marriage Rate",
       y = "Counterfactual Divorce Rate",
       title = "Total counterfactual effect of halving M on D") +
  theme_minimal()

gridExtra::grid.arrange(p2, p1, nrow = 1)
```

**5H3.**

We will need to build two models: one for the entire DAG and one that models the effect of $M$ on $N$.

```{r}
m_5h3 <- quap(
  alist(
        k ~ dnorm(mu, sigma),
        mu <- a + bm * m + bn * n,
        a ~ dnorm(0, 0.2),
        bm ~ dnorm(0, 0.5),
        bn ~ dnorm(0, 0.5),
        sigma ~ dexp(1),
        n ~ dnorm(mu_n, sigma_n),
        mu_n <- a_n + b_m * m,
        a_n ~ dnorm(0, 0.2),
        b_m ~ dnorm(0, 0.5),
        sigma_n ~ dexp(1)
  ),
  data = md_complete
)

# summary of parameters
precis(m_5h3)
```

Now, we begin our counterfactual investigation following the recipe starting on p. 141 of the text.

```{r}
# Double M and standardize with the original variable's mean and sd. M is 
# on a log scale, so we add log(2) in order to double M on the original scale.
m_seq <- (log(2) + md_complete$m - mean(md_complete$m)) / sd(md_complete$m)
sim_d <- data.frame(m = m_seq)

# Simulate N and K
s <- sim(m_5h3, data = sim_d, vars = c("n", "k"))

# Create data for plotting
plot_data_5h3 <- sim_d |>
  mutate(mu_n = colMeans(s$n),
         mu_k = colMeans(s$k))

pi_kn <- s |>
  lapply(\(x) apply(x, 2, PI)) |>
  lapply(\(x) as_tibble(t(x))) |>
  imap(\(x, i) `colnames<-`(x, paste(i, c("lower", "upper"), sep = "_"))) |>
  bind_cols()

plot_data_5h3 <- bind_cols(plot_data_5h3, pi_kn)

# Plot the counterfactual effects
p1 <- plot_data_5h3 |>
  ggplot(aes(x = m)) + 
  geom_line(aes(y = mu_k)) +
  geom_ribbon(aes(ymin = k_lower, ymax = k_upper),
              color = "gray", alpha = 0.3) +
  labs(x = "Manipulated M", y = "Counterfactual K",
       title = "Total counterfactual effect on K of doubling M") +
  theme_classic()
p2 <- plot_data_5h3 |>
  ggplot(aes(x = m)) + 
  geom_line(aes(y = mu_n)) +
  geom_ribbon(aes(ymin = n_lower, ymax = n_upper), color = "gray", alpha = 0.3) +
  labs(x = "Manipulated M", y = "Counterfactual N",
       title = "Counterfactual effect on N of doubling M") +
  theme_classic()

gridExtra::grid.arrange(p1, p2, ncol = 2)
```

**5H4.**

My first thought is that "Southerness" influences the age at marriage, which, in turn, influences the divorce and marriange rates as detailed in the text (starting on p. 129). In the South, the influence of America's Judeo-Christian heritage and its positive view on marriage is stronger than in other regions. Therefore, Southerners tend to marry earlier than in other regions. But, as explained in the text, getting married younger allows for more opportunity for divorce. 

The DAG illustrating this is a slight modification of the one on p. 129 with the variable $S$ representing the binary variable of "Southerness".

```{r}
south_dag <- dagitty("dag{S -> A; A -> M; A -> D}")
coordinates(south_dag) <- list(
  x = c(A = 0, D = 1, M = 2, S = 0),
  y = c(A = 0, D = 1, M = 0, S = -1)
)
drawdag(south_dag)

# Implied conditional independencies
impliedConditionalIndependencies(south_dag)
```

We can now test the various conditional independencies implied by this DAG by building models. First note that the independence of $D$ and $M$ conditional on $A$ was already investigated in the text, so we will focus on the other two.

```{r}
# Convert the dummy variable `South` to an index where 1 means non-Southern and
# 2 means Southern
wd_lds$south <- as.integer(wd_lds$South + 1)
# Modeling the DAG
m_5h4 <- quap(
  alist(
    # S -> A
    age ~ dnorm(mu_age, sigma_age),
    mu_age <- a_age[south],
    a_age[south] ~ dnorm(0, 0.5),
    sigma_age ~ dunif(0, 50),
    # A -> D <- M
    div ~ dnorm(mu, sigma),
    mu <- a + bm * mar + ba * age,
    a ~ dnorm(0, 0.2),
    bm ~ dnorm(0, 0.5),
    ba ~ dnorm(0, 0.5),
    sigma ~ dexp(1),
    # A -> M
    mar ~ dnorm(mu_mar, sigma_mar),
    mu_mar <- a_mar + ba2 * age,
    a_mar ~ dnorm(0, 0.2),
    ba2 ~ dnorm(0, 0.5),
    sigma_mar ~ dexp(1)
  ),
  data = wd_lds
)
# Model divorce and southerness
m_div_south <- quap(
  alist(
    div ~ dnorm(mu, sigma),
    mu <- a[south],
    a[south] ~ dnorm(0, 0.5),
    sigma ~ dexp(1)
  ),
  data = wd_lds
)
precis(m_div_south, depth = 2)

```
precis(m_5h4, depth = 2)

mu <- link(m_5h4)
mu_mean <- map_df(mu, \(x) apply(x, 2, mean)) |>
  bind_cols(wd_lds[, c("div", "mar", "age", "south")])
mu_resid <- mu_mean |>
  mutate(resid_mar = mar - mu_mar,
         resid_div = div - mu,
         resid_age = age - mu_age)

mu_resid |>
  ggplot() +
  geom_point(aes(x = resid_age, div))
```
